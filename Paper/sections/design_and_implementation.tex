\label{sec:design_and_implementation}
To implement an agent that reasons logically about regions and takes advantage of simulation software to do path finding, it is necessary to choose the most suitable tools.
Since there is no framework for implementing BDI agents on major game engines, it was necessary to separate the two components and create a connection between them.
The first component handles the intelligent agent and the second handles the physical body and environment. The framework must ensure a 1-to-1 connection between the BDI agent and its body.
The architecture can be seen in Figure\ref{fig:architecture}.

\begin{figure}
    \centering
    \input{sections/tikz/architecture.tex}
    \label{fig:architecture}
    \caption{The architecture of the system}
\end{figure}

The section is now divided into three subsections. The first lays some fundamentals to be shared by agent and environment on the Region Connection Calculus (RCC) and the environment in which the simulation will take place, the second presents the design and implementation of the BDI agent, and the third follows the same path for the virtual environment.

\subsection{Environment and Regions}
The environment and agent must properly implement the principles of Region Connection Calculus (RCC) introduced by D. A. Randell, Z. Cui and A. G. Cohn\cite{DBLP:conf/kr/RandellCC92}.
RCC provides some basic relationships between regions that are visible in Figure\ref{fig:relations}.
With these relationships it is possible to describe any environment qualitatively, abstracting from coordinates $(x, y)$ and focusing instead on regions.
The relations that turn out to be most used within this work are \texttt{EC(A, B)}, \texttt{PO(A, B)} and \texttt{NTPP(A, B)}, which are the essential relations to be able to find an object within a region and know which regions border on which others in order to move between them.

\begin{figure}
    \centering
    \input{sections/tikz/relations.tex}
    \label{fig:relations}
    \caption{Relations between regions}
\end{figure}

The problem of robot vacuum cleaning is to remove all the dirt from the floor. 
The relation that carries this information is \texttt{NTPP(dirt, Region)} where Region is the region where the dirt is actually contained.
We then decided to include another hierarchical concept to make the reasoning finer, adding the concept of a room.
Each region is then found contained within a room with the relation \texttt{NTPP(Region, Room)}.
The rooms are then connected by doors.
Doors are considered as regions that have intersection with both one room and the other (\texttt{PO(door, Room1)}, \texttt{PO(door, Room2)}) but are not contained in either.
Only the regions that are traversable by the robot are considered in this initial work without taking into account the objects in the room that are only handled by the simulation side of the framework for the time being.
The regions within a room are all close but without overlapping, thus respecting the relation \texttt{EC(Region1, Region2)}.

In order to give a proof of concept in an environment that was as verisimilar and nontrivial as possible, the study room of computer science PhD students at the University of Genoa was considered as a virtual environment.
This environment can be seen in Figure\ref{fig:environment}.
Using the representation of a real environment makes the simulation nontrivial and verisimilar.

\begin{figure}
    \centering
    \input{sections/tikz/env.tex}
    \label{fig:environment}
    \caption{The test environment}
\end{figure}

The study room is divided into 4 rooms, from left to right: the common room (not considered for the current implementation), room 309, room 310 and at the top room 314.
There are workstations and cabinets in each of the rooms.
They were divided into hard-coded regions based on the location of the desks, trying to find the right balance between the whole room and excessive granularity.

Regions for the moment are only areas in the environment while they are terms for the agent. 
Obviously, the relationships between regions considered by the agent must respect what is present in the environment and vice versa, and the agent must always have an understanding of the region it is in.

\subsection{Agent: Design and Implementation}
The agent is based on the BDI paradigm and knows the entire map through RCC. 
We want to avoid in any way that the agent has Cartesian cognition of the space it is in.

The agent aims to remove all the dirt in the room and has two plans for doing so:
\begin{enumerate}
    \item \textit{clean}: removes the dirt;
    \item \textit{reach}: a plan that tells the body which region it wants to reach among those adjacent to the one it is in.
\end{enumerate}
The agent must know the logical map of the room and updates the region it is in as it goes, always keeping the term as ground as possible, the smallest region occupied by the agent.
Ultimately, the agent must be able to reason about the paths to be taken to reach its goal.
To do this requires an additional plan to be interrogated to find a sequence of noncyclic adiancent regions from the current region to the desired region.
The agent must then have a way to connect to his or her body to send requests and receive information.

The implementation was done using JaCaMo\cite{jacamo}.
As a first step, the agent creates an artifact that establishes the connection with the physical body.
The artifact then turns out to be owned by the agent, making this direct connection between agent and body without further intermediaries.
The agent then executes the \texttt{find\_and\_clean} plan, which aims to remove all the dirt in the room. 

The plan has three variants that are recursively referred to.
The first has as preconditions that there is still at least one dirt to be cleaned and that that dirt is in the same region as the agent.
In this case the agent must ask the body to reach the dirt and once it reaches it, clean it.
When it receives confirmation of the cleaning it removes that dirt from its beliefs and calls \texttt{find\_and\_clean}.
\begin{lstlisting}[language=AgentSpeak]
+!go_to_clean
    :   ntpp(Dirt, Region) & my_region(Region) & dirt(Dirt)
    <-  gain(Dirt);
        .wait({+gained});
        clean(Dirt);
        .wait({+cleaned});
        -ntpp(Dirt, Region);
        !go_to_clean.
\end{lstlisting}
The second, on the other hand, only predicts that there is still dirt.
If the agent uses this plan, it is because the dirt is not in the same region and therefore must move to the region where the dirt is contained.
To do this, the agent has another plan \texttt{move\_to} that allows it to reach the region where the dirt is.
\begin{lstlisting}[language=AgentSpeak]
+!go_to_clean
    :   ntpp(Dirt, Region) & dirt(Dirt)
    <-  !move_to(Region);
        !go_to_clean.
\end{lstlisting}
The \texttt{move\_to} plan also has variations.
In particular, it must take into account the room in which it is located; if in fact the region sought is in another room, the agent must look for a door that will take him into it, reach it, and then once inside it find the path to the region in which the dirt is located or another door if necessary.
If, on the other hand, he is in the same room, he must find and follow the sequence of regions that lead him to the desired one.
The \texttt{move\_to} plan, in addition to finding the path is also concerned with following it, that is, waiting until a message has arrived for each region from the body indicating that it has been reached before moving on to consider the next one with the \texttt{follow\_path} plan.
\begin{lstlisting}[language=AgentSpeak]
+!move_to(region)
    :   my_region(CurrentRegion) & 
        not sameroom(CurrentRegion, Region) & 
        ntpp(Region, Room) & ec(Door, Room)
    <-  ?find_path(CurrentRegion, Door, Path);
        .reverse(Path, ReversePath);
        !follow_path(ReversePath);
        !move_to(Region).

+!move_to(Region)
    :   my_region(CurrentRegion)
    <-  ?find_path(CurrentRegion, Region, Path);
        .reverse(Path, ReversePath);
        !follow_path(ReversePath).
\end{lstlisting}
For the time being, no path search optimization logic is implemented but simply the agent searches for one that is walkable.

Finally, the agent has a \texttt{clean} plan that allows it to remove dirt by communicating to its body to perform the action.
This plan is called when the agent is on dirt and is the one that eliminates it.
It has no preconditions, because indeed a robot vacuum cleaner can vacuum even where it is already clean, it is the \texttt{find\_and\_clean} plan that calls it at the right time.

Finally, communication with Godot is implemented within the Java artifact that implements a Websocket client and can send two types of messages:
\begin{itemize}
    \item \lstinline|{"type": "gain", "target": Target}|: sent to reach a Target region;
    \item \lstinline|{"type": "clean", "target": Target}|: sent to clean the Target dirt.
\end{itemize}

\subsection{Environment: Design and Implementation}
The environment must represent the map presented in Figure\ref{fig:environment} with the due physical characteristics of the objects and walls and must handle agent displacement and dirt removal.
The regions must be inserted into the scene in a physical way: the robot must not reason about them, it must find path and realize it has reached the region, so they must be something the robot can virtually interact with.
Note that regions also need to be inserted at doors that make it possible to pass from one room to another.

The environment was implemented with Godot.
Godot is an open-source game development software that allows to place objects within a 3D virtual environment and attach scripts to some objects.
The environment was built as visible in Figure\ref{fig:godot} respecting the features shown in Figure\ref{fig:environment}.
Regions have been implemented in this version as \texttt{Marker3D}s and thus as individual points near which the agent must pass.
The robot is implemented as \texttt{CharacterBody3D} and has attached a script that implements agent connection, movement, and dirt removal.

\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{sections/imgs/env.png}
    \label{fig:godot}
    \caption{The Godot environment}
\end{figure}

The \texttt{NavigationRegion3D} node was used to implement path finding. This type of node creates a map of walkable surfaces from the nodes it has as children.
In our case the entire environment except the vacuum cleaner itself is instantiated as a child of this node, making everything walkable.
The robot is then implemented using the \texttt{CharacterBody3D} node as its main with a \texttt{NavigationAgent3D} as its child that implements the robot's walk on the map given by the NavigationRegion3D.
The algorithm that is used by the \texttt{NavigationAgent3D} to find the best path is a version of A$^\star$ on the continuum with steps of unfixed length.

%\begin{figure}
%    \centering
%    \includegraphics[scale=0.4]{sections/imgs/trajectory.png}
%    \label{fig:trajectory}
%    \caption{The followed trajectory}
%\end{figure}

The connection is implemented as a WebSocket Server directly within the script so again the robot communicates directly with its agent.
This creates a 1-to-1 agent-robot correlation that may be useless for the moment but is game changing as we move from a single agent to having multiple agents and multiple robots in the same environment.

When the agent sends a message to the robot of type \texttt{\{"type": "gain", "target": "regionX"\}} the received region is entered as the target of NavigatAgent3D.
It then calculates the shortestPath to reach it and follows it step by step. The robot's degrees of rotation are not constrained in any way, nor is the length of the space it travels at each step.
When it has reached the goal it sends a message \texttt{\{"type": "inform", "code": "gained"\}} to the agent informing it that it is ready to perform the next task, be it moving to another region or cleaning up.
If the agent requests cleaning then the node depicting dirt from the robot is destroyed and a message \texttt{\{"type": "inform", "code": "cleaned"\}} is sent to the agent awaiting new instructions.